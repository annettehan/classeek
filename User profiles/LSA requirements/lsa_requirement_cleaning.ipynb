{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from easydict import EasyDict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_files = glob.glob('*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_course_col(df):\n",
    "    subject = df['Subject']\n",
    "    df['Subject'] = df['Subject'].astype(str)\n",
    "    df['subject'] = [s[s.find(\"(\") + 1:s.find(\")\")] for s in subject]\n",
    "    df['Catalog Nbr'] = df['Catalog Nbr'].astype(str)\n",
    "    df['course'] = df['subject'] + ' ' + df['Catalog Nbr']\n",
    "    df.sort_values(by=['course'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in excel_files:\n",
    "    df = pd.read_excel(file)    \n",
    "    if 'Catalog Nbr' not in df.columns:\n",
    "        df.rename(columns={'Catalog': 'Catalog Nbr',\n",
    "                           'Descr': 'title'}, inplace=True)\n",
    "        create_course_col(df)\n",
    "        df.to_csv(f'{file}.csv', index=False)\n",
    "    else: print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FYWR CLST 3509.xlsx.csv',\n",
       " 'SS Courses Offered FA21.xlsx.csv',\n",
       " 'FYWR CLST 20.xlsx.csv',\n",
       " 'QR2 CLST 1329.xlsx.csv',\n",
       " 'HU Courses Offered FA21.xlsx.csv',\n",
       " 'Lang Req CLST 8140.xlsx.csv',\n",
       " 'Lang Req CLST 0176.xlsx.csv',\n",
       " 'QR1 CLST 9561 Exclusions.xlsx.csv',\n",
       " 'ID Courses Offered FA21.xlsx.csv',\n",
       " 'QR1 CLST 1331.xlsx.csv',\n",
       " 'MSA Courses Offered FA21.xlsx.csv',\n",
       " 'CE Courses Offered FA21.xlsx.csv',\n",
       " 'NS Courses Offered FA21.xlsx.csv',\n",
       " 'RE CLST 4609.xlsx.csv',\n",
       " 'Lang Req CLST 3474.xlsx.csv',\n",
       " 'QR1 CLST 1817.xlsx.csv',\n",
       " 'Lang Req CLST 0179.xlsx.csv',\n",
       " 'RE CLST 4621.xlsx.csv',\n",
       " 'RE CLST 4620.xlsx.csv',\n",
       " 'Courses with ULWR Course Attributes.xlsx.csv',\n",
       " 'w_22_des.csv',\n",
       " 'f_21_des.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat Each Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_each_requirement(files):\n",
    "    \n",
    "    file_list = []\n",
    "    \n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        file_list.append(df)\n",
    "    \n",
    "    df = pd.concat(file_list, axis=0, ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Scraped Course Description Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_scraped_course_des_files(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df.dropna(subset=['catalog_number'], inplace=True)\n",
    "    df = df.fillna('')\n",
    "    df['requirements_distribution'] = df['requirements_distribution'] + ', ' + df['other']\n",
    "    df['requirements_distribution'] = [x.split(', ') for x in df['requirements_distribution']]\n",
    "    \n",
    "    subject = df['subject']\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    df['subject'] = [s[s.find(\"(\") + 1:s.find(\")\")] for s in subject]\n",
    "    df['catalog_number'] = [int(i) for i in df['catalog_number']]\n",
    "    df['catalog_number'] = df['catalog_number'].astype(str)\n",
    "    df['course'] = df['subject'] + ' ' + df['catalog_number']\n",
    "    df.sort_values(by=['course'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_21 = read_scraped_course_des_files('f_21_des.csv')\n",
    "w_22 = read_scraped_course_des_files('w_22_des.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframes for each requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'BS',\n",
       " 'CBL',\n",
       " 'CE',\n",
       " 'Experiential',\n",
       " 'FYSem',\n",
       " 'FYWR',\n",
       " 'HU',\n",
       " 'Honors',\n",
       " 'ID',\n",
       " 'Independent',\n",
       " 'Lang Req',\n",
       " 'MSA',\n",
       " 'Minicourse',\n",
       " 'NS',\n",
       " 'QR/1',\n",
       " 'QR/2',\n",
       " 'RE',\n",
       " 'SS',\n",
       " 'Sustain',\n",
       " 'ULWR'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at all the requirements listed\n",
    "{x for l in w_22['requirements_distribution'] for x in l}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fywr = concat_each_requirement(['FYWR CLST 20.xlsx.csv', 'FYWR CLST 3509.xlsx.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulwr = pd.read_csv('Courses with ULWR Course Attributes.xlsx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr1 = concat_each_requirement(['QR1 CLST 9561 Exclusions.xlsx.csv', 'QR1 CLST 1817.xlsx.csv', 'QR1 CLST 1331.xlsx.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr2 = pd.read_csv('QR2 CLST 1329.xlsx.csv')\n",
    "re = concat_each_requirement(['RE CLST 4621.xlsx.csv', 'RE CLST 4620.xlsx.csv', 'RE CLST 4609.xlsx.csv'])\n",
    "lr = concat_each_requirement(['Lang Req CLST 0179.xlsx.csv', 'Lang Req CLST 3474.xlsx.csv', 'Lang Req CLST 0176.xlsx.csv', 'Lang Req CLST 8140.xlsx.csv'])\n",
    "ns = pd.read_csv('NS Courses Offered FA21.xlsx.csv')\n",
    "ss = pd.read_csv('SS Courses Offered FA21.xlsx.csv')\n",
    "hu = pd.read_csv('HU Courses Offered FA21.xlsx.csv')\n",
    "msa = pd.read_csv('MSA Courses Offered FA21.xlsx.csv')\n",
    "ce = pd.read_csv('CE Courses Offered FA21.xlsx.csv')\n",
    "interdisciplinary = pd.read_csv('ID Courses Offered FA21.xlsx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def comprehensive_list_merge(requirement, requirement_df):\n",
    "    \n",
    "    w_22_requirement_df = w_22[w_22['requirements_distribution'].map(lambda x: requirement in x)]\n",
    "    f_21_requirement_df = f_21[f_21['requirements_distribution'].map(lambda x: requirement in x)]\n",
    "    \n",
    "    # Merge requirement_df with w_22_requirement_df\n",
    "    merge1 = w_22_requirement_df.merge(requirement_df[['course', 'title']], on=['course', 'title'], how='outer')\n",
    "    \n",
    "    # Concat this df with f_21_requirement_df\n",
    "    merge2 = pd.concat([merge1, f_21_requirement_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    # Drop duplicate courses\n",
    "    merge2.drop_duplicates(subset='course', inplace=True)\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    merge2 = merge2[['course', 'title', 'description', 'requirements_distribution', 'credits']]\n",
    "    \n",
    "    # Fill na with the requirement\n",
    "    merge2['requirements_distribution'] = merge2['requirements_distribution'].fillna(requirement)\n",
    "    \n",
    "    # Fill na in credits column with medians\n",
    "    merge2['credits'] = pd.to_numeric(merge2['credits'], errors='coerce')\n",
    "    merge2['credits'] = merge2['credits'].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    # Add col requirement\n",
    "    merge2['df_requirement'] = requirement\n",
    "    \n",
    "    return merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fywr_df = comprehensive_list_merge('FYWR', fywr)\n",
    "ulwr_df = comprehensive_list_merge('ULWR', ulwr)\n",
    "qr1_df = comprehensive_list_merge('QR/1', qr1)\n",
    "qr2_df = comprehensive_list_merge('QR/2', qr2)\n",
    "re_df = comprehensive_list_merge('RE', re)\n",
    "lr_df = comprehensive_list_merge('Lang Req', lr)\n",
    "ns_df = comprehensive_list_merge('NS', ns)\n",
    "ss_df = comprehensive_list_merge('SS', ss)\n",
    "hu_df = comprehensive_list_merge('HU', hu)\n",
    "msa_df = comprehensive_list_merge('MSA', msa)\n",
    "ce_df = comprehensive_list_merge('CE', ce)\n",
    "id_df = comprehensive_list_merge('ID', interdisciplinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_df = pd.concat([w_22[w_22['requirements_distribution'].map(lambda x: 'BS' in x)], f_21[f_21['requirements_distribution'].map(lambda x: 'BS' in x)]], axis=0, ignore_index=True)\n",
    "cbl_df = pd.concat([w_22[w_22['requirements_distribution'].map(lambda x: 'CBL' in x)], f_21[f_21['requirements_distribution'].map(lambda x: 'CBL' in x)]], axis=0, ignore_index=True)\n",
    "ex_df = pd.concat([w_22[w_22['requirements_distribution'].map(lambda x: 'Experiential' in x)], f_21[f_21['requirements_distribution'].map(lambda x: 'Experiential' in x)]], axis=0, ignore_index=True)\n",
    "honors_df = pd.concat([w_22[w_22['requirements_distribution'].map(lambda x: 'Honors' in x)], f_21[f_21['requirements_distribution'].map(lambda x: 'Honors' in x)]], axis=0, ignore_index=True)\n",
    "ind_df = pd.concat([w_22[w_22['requirements_distribution'].map(lambda x: 'Independent' in x)], f_21[f_21['requirements_distribution'].map(lambda x: 'Independent' in x)]], axis=0, ignore_index=True)\n",
    "mini_df = pd.concat([w_22[w_22['requirements_distribution'].map(lambda x: 'Minicourse' in x)], f_21[f_21['requirements_distribution'].map(lambda x: 'Minicourse' in x)]], axis=0, ignore_index=True)\n",
    "sus_df = pd.concat([w_22[w_22['requirements_distribution'].map(lambda x: 'Sustain' in x)], f_21[f_21['requirements_distribution'].map(lambda x: 'Sustain' in x)]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate LSA Degree Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lsa_requirement(quant):\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    one_list = [fywr_df, ulwr_df, re_df]\n",
    "\n",
    "    courses_taken = []\n",
    "    require = []\n",
    "    title = []\n",
    "    credit = []\n",
    "\n",
    "    # FYWR, ULWR, RE requirements, 1 course each\n",
    "    for req_df in one_list:\n",
    "\n",
    "        req_course = rng.choice(req_df['course'], size=1, replace=False)[0]\n",
    "        req = req_df[req_df['course'] == req_course]['df_requirement'].values[0]\n",
    "        course_title = req_df[req_df['course'] == req_course]['title'].values[0]\n",
    "        req_credit = req_df[req_df['course'] == req_course]['credits'].values[0]\n",
    "\n",
    "        courses_taken.append(req_course)\n",
    "        require.append(req)\n",
    "        title.append(course_title)\n",
    "        credit.append(req_credit)\n",
    "    \n",
    "    # QR requirement, 1 of QR/1 or 2 of QR/2\n",
    "    if quant == 'QR/1':\n",
    "\n",
    "        qr1_course = rng.choice(qr1_df['course'], size=1, replace=False)[0]\n",
    "        qr1 = 'QR/1'\n",
    "        qr1_title = qr1_df[qr1_df['course'] == qr1_course]['title'].values[0]\n",
    "        qr1_credit = qr1_df[qr1_df['course'] == qr1_course]['credits'].values[0]\n",
    "\n",
    "        courses_taken.append(qr1_course)\n",
    "        require.append(qr1)\n",
    "        title.append(qr1_title)\n",
    "        credit.append(qr1_credit)\n",
    "\n",
    "    if quant == 'QR/2':\n",
    "\n",
    "        qr2_course = rng.choice(qr2_df['course'], size=2, replace=False)\n",
    "\n",
    "        qr21_course = qr2_course[0]\n",
    "        qr21 = 'QR/2'\n",
    "        qr21_title = qr2_df[qr2_df['course'] == qr21_course]['title'].values[0]\n",
    "        qr21_credit = qr2_df[qr2_df['course'] == qr21_course]['credits'].values[0]\n",
    "\n",
    "        qr22_course = qr2_course[1]\n",
    "        qr22 = 'QR/2'\n",
    "        qr22_title = qr2_df[qr2_df['course'] == qr22_course]['title'].values[0]\n",
    "        qr22_credit = qr2_df[qr2_df['course'] == qr22_course]['credits'].values[0]\n",
    "\n",
    "        courses_taken.extend([qr21_course, qr22_course])\n",
    "        require.extend([qr21, qr22])\n",
    "        title.extend([qr21_title, qr22_title])\n",
    "        credit.extend([qr21_credit, qr22_credit])\n",
    "        \n",
    "    # Language requirement, fourth-term language course (or credits for four courses)\n",
    "    \n",
    "    lr_courses = rng.choice(lr_df['course'], size=4, replace=False)\n",
    "    lr = np.repeat('LR', 4)\n",
    "    \n",
    "    lr_titles = []\n",
    "    for lr_course in lr_courses:\n",
    "        lr_title = lr_df[lr_df['course'] == lr_course]['title'].values[0]\n",
    "        lr_titles.append(lr_title)\n",
    "    \n",
    "    lr_credits = []\n",
    "    for lr_course in lr_courses:\n",
    "        lr_credit = lr_df[lr_df['course'] == lr_course]['credits'].values[0]\n",
    "        lr_credits.append(lr_credit)\n",
    "        \n",
    "    courses_taken.extend(lr_courses)\n",
    "    require.extend(lr)\n",
    "    title.extend(lr_titles)\n",
    "    credit.extend(lr_credits)\n",
    "        \n",
    "    # Area Distribution requirement\n",
    "    # 7 credits in each of NS, SS, and HU for a total of 21 credits or more\n",
    "    \n",
    "    # NS\n",
    "    total_ns_credits = 0\n",
    "    ns_courses = []\n",
    "    ns_reqs = []\n",
    "    ns_course_credits = []\n",
    "    ns_course_titles = []\n",
    "\n",
    "    while total_ns_credits < 7:\n",
    "        ns_course = rng.choice(ns_df['course'], size=1, replace=False)[0]\n",
    "        ns_req = ns_df[ns_df['course'] == ns_course]['df_requirement'].values[0]\n",
    "        ns_course_credit = ns_df[ns_df['course'] == ns_course]['credits'].values[0]\n",
    "        ns_course_title = ns_df[ns_df['course'] == ns_course]['title'].values[0]\n",
    "        total_ns_credits+=ns_course_credit\n",
    "        \n",
    "        ns_courses.append(ns_course)\n",
    "        ns_reqs.append(ns_req)\n",
    "        ns_course_credits.append(ns_course_credit)\n",
    "        ns_course_titles.append(ns_course_title)\n",
    "        \n",
    "    # SS\n",
    "    total_ss_credits = 0\n",
    "    ss_courses = []\n",
    "    ss_reqs = []\n",
    "    ss_course_credits = []\n",
    "    ss_course_titles = []\n",
    "\n",
    "    while total_ss_credits < 7:\n",
    "        ss_course = rng.choice(ss_df['course'], size=1, replace=False)[0]\n",
    "        ss_req = ss_df[ss_df['course'] == ss_course]['df_requirement'].values[0]\n",
    "        ss_course_credit = ss_df[ss_df['course'] == ss_course]['credits'].values[0]\n",
    "        ss_course_title = ss_df[ss_df['course'] == ss_course]['title'].values[0]\n",
    "        total_ss_credits+=ss_course_credit\n",
    "        \n",
    "        ss_courses.append(ss_course)\n",
    "        ss_reqs.append(ss_req)\n",
    "        ss_course_credits.append(ss_course_credit)\n",
    "        ss_course_titles.append(ss_course_title)\n",
    "        \n",
    "    # HU\n",
    "    total_hu_credits = 0\n",
    "    hu_courses = []\n",
    "    hu_reqs = []\n",
    "    hu_course_credits = []\n",
    "    hu_course_titles = []\n",
    "\n",
    "    while total_hu_credits < 7:\n",
    "        hu_course = rng.choice(hu_df['course'], size=1, replace=False)[0]\n",
    "        hu_req = hu_df[hu_df['course'] == hu_course]['df_requirement'].values[0]\n",
    "        hu_course_credit = hu_df[hu_df['course'] == hu_course]['credits'].values[0]\n",
    "        hu_course_title = hu_df[hu_df['course'] == hu_course]['title'].values[0]\n",
    "        total_hu_credits+=hu_course_credit\n",
    "        \n",
    "        hu_courses.append(hu_course)\n",
    "        hu_reqs.append(hu_req)\n",
    "        hu_course_credits.append(hu_course_credit)\n",
    "        hu_course_titles.append(hu_course_title)\n",
    "        \n",
    "    # 3 additional credits in three of five areas NS, SS, HU, MSA, and CE for total of 9 credits or more\n",
    "    \n",
    "    three_additional_credits = [ns_df, ss_df, hu_df, msa_df, ce_df]\n",
    "    \n",
    "    three_areas = rng.choice(three_additional_credits, size=3, replace=False)\n",
    "    \n",
    "    area_1_df = three_areas[0]\n",
    "    area_1_course = rng.choice(area_1_df['course'], size=1, replace=False)[0]\n",
    "    area_1_req = area_1_df[area_1_df['course'] == area_1_course]['df_requirement'].values[0]\n",
    "    area_1_credit = area_1_df[area_1_df['course'] == area_1_course]['credits'].values[0]\n",
    "    area_1_title = area_1_df[area_1_df['course'] == area_1_course]['title'].values[0]\n",
    "\n",
    "    area_2_df = three_areas[1]\n",
    "    area_2_course = rng.choice(area_2_df['course'], size=1, replace=False)[0]\n",
    "    area_2_req = area_2_df[area_2_df['course'] == area_2_course]['df_requirement'].values[0]\n",
    "    area_2_credit = area_2_df[area_2_df['course'] == area_2_course]['credits'].values[0]\n",
    "    area_2_title = area_2_df[area_2_df['course'] == area_2_course]['title'].values[0]\n",
    "\n",
    "    area_3_df = three_areas[2]\n",
    "    area_3_course = rng.choice(area_3_df['course'], size=1, replace=False)[0]\n",
    "    area_3_req = area_3_df[area_3_df['course'] == area_3_course]['df_requirement'].values[0]\n",
    "    area_3_credit = area_3_df[area_3_df['course'] == area_3_course]['credits'].values[0]\n",
    "    area_3_title = area_3_df[area_3_df['course'] == area_3_course]['title'].values[0]\n",
    "\n",
    "    # Extend all these courses to the list\n",
    "    courses_taken.extend([area_1_course, area_2_course, area_3_course])\n",
    "    courses_taken = courses_taken + ns_courses + ss_courses + hu_courses\n",
    "    \n",
    "    require.extend([area_1_req, area_2_req, area_3_req])\n",
    "    require = require + ns_reqs + ss_reqs + hu_reqs\n",
    "    \n",
    "    title.extend([area_1_title, area_2_title, area_3_title])\n",
    "    title = title + ns_course_titles + ss_course_titles + hu_course_titles\n",
    "    \n",
    "    credit.extend([area_1_credit, area_2_credit, area_3_credit])\n",
    "    credit = credit + ns_course_credits + ss_course_credits + hu_course_credits \n",
    "\n",
    "    # Create a df\n",
    "    require_df = pd.DataFrame({'Subject/Catalog': courses_taken, 'Course List Description': require, \n",
    "                                   'Credits': credit, 'Course Title': title})\n",
    "    \n",
    "    require_df['Rating'] = np.random.uniform(low=2, high=5, size=(len(require_df)))\n",
    "    \n",
    "#     total_credits = sum(credit)\n",
    "\n",
    "    return require_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_student(number_student, quant):\n",
    "    \n",
    "    gen_student_df_dict = {}\n",
    "\n",
    "    for i in range(number_student):\n",
    "        gen_df = gen_lsa_requirement(quant)\n",
    "        gen_student_df_dict[i] = gen_df\n",
    "        \n",
    "    return gen_student_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr1_students = gen_student(2500, 'QR/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr2_students = gen_student(2500, 'QR/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(qr1_students, open(\"qr1_students.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(qr2_students, open(\"qr2_students.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate profile clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_21_merged = pd.read_csv('f_21_merge.csv')\n",
    "w_22_merged = pd.read_csv('w_22_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel, sigmoid_kernel\n",
    "import neattext.functions as nfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
