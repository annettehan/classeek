{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "### read_data(file_path)\n",
    "- read data to df\n",
    "\n",
    "### concat_user_input_and_convert_to_csr(df, user_input): \n",
    "- df: output df from read_data\n",
    "- user_input: list of courses the user provide\n",
    "- Append user input to the df and convert the df into csr. \n",
    "- Returns csr matrix, and course list.\n",
    "\n",
    "### svd_based(uc_mat, courses, user_idx = -1, num_factors=80, top_n = 10, random_state=42):\n",
    "- uc_mat: csr matrix (1st output of concat_user_input_and_convert_to_csr)\n",
    "- courses: course list (2nd output of concat_user_input_and_convert_to_csr)\n",
    "- num_factors: hyperparam of svd\n",
    "- top_n: num of recommendation\n",
    "- Returns top_n recommended courses\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook\n",
    "* Try three different collaborative filterings: Memory, SVD, NMF\n",
    "* Speed: SVD - Memory - NMF (fast to slow)\n",
    "* RMSE: SVD - NMF - Memory (low to high)\n",
    "\n",
    "\n",
    "* Winner: SVD\n",
    "\n",
    "## Note\n",
    "* Parameter tuning (SVD: num_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and convert into sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    from scipy.sparse import csr_matrix\n",
    "    \n",
    "    # Read pickle\n",
    "    stu = pd.read_pickle(file_path)\n",
    "    \n",
    "    # Num of dictionaries in the file\n",
    "    n = len(stu)\n",
    "    \n",
    "    # Initialize df\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Loop through dicts and concat\n",
    "    for i in range(n):\n",
    "        stu[i]['student_id'] = i\n",
    "        df = pd.concat([df,stu[i]])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def concat_user_input_and_convert_to_csr(df, user_input):\n",
    "    # df = user dataset we have\n",
    "    # user_input: courses that user provide\n",
    "\n",
    "    # User input to df and concat\n",
    "    user_df = pd.DataFrame()\n",
    "    user_df['Subject/Catalog'] = user_input\n",
    "    user_df['Rating'] = 1\n",
    "    user_df['student_id'] = df['student_id'].max()+1\n",
    "\n",
    "    df = pd.concat([df, user_df])\n",
    "    # Fix .0 issues -- Some courses has .0 at the end (e.g. AAS 101.0), remove .0\n",
    "    df.loc[df['Subject/Catalog'].str.contains('\\.') == True, 'Subject/Catalog'] = df.loc[df['Subject/Catalog'].str.contains('\\.') == True, 'Subject/Catalog'].str.split('\\.').str[0]\n",
    "    \n",
    "    # Pivot table to stu - course\n",
    "    df = pd.pivot_table(df, values = 'Rating', index = 'student_id', columns = 'Subject/Catalog')\n",
    "    \n",
    "    # Fillna\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # df to sparse matrix\n",
    "    csr = csr_matrix(df)\n",
    "    \n",
    "    # Store course names\n",
    "    courses = list(df.columns)\n",
    "    \n",
    "    # Get matched user by cos sim -- uncomment this if we use this information\n",
    "    #matched_user_idx = np.argsort(cosine_similarity(csr)[-1])[-2] #Best match of stu_idx -1 \n",
    "    \n",
    "    return csr, courses #matched_user_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def svd_based(uc_mat, courses, num_factors=80, top_n = 10, random_state=42):\n",
    "    # SVD based collaborative filtering\n",
    "    \n",
    "    # user_idx = -1\n",
    "    user_idx = -1\n",
    "    \n",
    "    # SVD\n",
    "    svd = TruncatedSVD(n_components = num_factors, random_state = random_state)\n",
    "    \n",
    "    # Transform X\n",
    "    X_transformed = svd.fit_transform(uc_mat)\n",
    "    \n",
    "    # Calculate r\n",
    "    r = np.matmul(X_transformed, svd.components_)\n",
    "    \n",
    "    # Pred rating\n",
    "    pred_rating = r[user_idx,:]#.reshape(1,-1)\n",
    "    \n",
    "    \n",
    "    # Matched user vector\n",
    "    user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "    \n",
    "    \n",
    "    # User's favorite course indices\n",
    "    user_fav_idx = np.argsort(-user_vec)\n",
    "    \n",
    "    # User's favorite courses\n",
    "    #user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "    #print(f\"Top {top_n} favorite courses:\")\n",
    "    #print(user_fav)\n",
    "\n",
    "    \n",
    "    # Flatten pred_rating\n",
    "    pred_rating = np.asarray(pred_rating).flatten()\n",
    "    \n",
    "    # Argsort the rating except the courses taken by the user\n",
    "    recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "    \n",
    "    # Recommend top courses\n",
    "    top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "    \n",
    "    print(f\"Top {top_n} recommended courses:\")\n",
    "    print(top_courses)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # RMSE between true & predicted. Uncomment the next two lines to see RMSE\n",
    "    rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2))\n",
    "    print(f\"RMSE = {rmse}\")\n",
    "    \n",
    "    return top_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommended courses:\n",
      "['EECS 581', 'EECS 385', 'EECS 482', 'RELIGIO 310', 'EECS 473', 'EECS 487', 'ENVIRO 167', 'EECS 490', 'EECS 280', 'SA 315']\n",
      "\n",
      "RMSE = 4.320117968276276\n",
      "CPU times: user 793 ms, sys: 117 ms, total: 911 ms\n",
      "Wall time: 418 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = svd_based(csr, courses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "uc_mat = csr\n",
    "user_idx = 0\n",
    "\n",
    "def memory_based(uc_mat, user_idx, top_n):\n",
    "    # Memory-based collaborative filtering\n",
    "    \n",
    "    # Normalize user-course matrix\n",
    "    norm_uc_mat = uc_mat - uc_mat.mean(axis = 1).reshape(-1,1)\n",
    "    \n",
    "    # Cosine similarity of raw matrix\n",
    "    cossim = cosine_similarity(uc_mat)\n",
    "    \n",
    "    # Calculate the numerator of V-hat(aj)\n",
    "    v_num = np.dot(cossim[user_idx,:], norm_uc_mat)\n",
    "    \n",
    "    # Sum of V-hat(aj) numerator\n",
    "    v_num_sum = v_num.sum(axis = 0)\n",
    "    \n",
    "    # V_hat(aj)\n",
    "    v_hat = v_num_sum/(cossim[user_idx,:].sum())\n",
    "    \n",
    "    #Predicted rating of each course\n",
    "    pred_rating = np.add(v_hat, uc_mat.mean(axis = 1).reshape(-1,1)[user_idx])\n",
    "    \n",
    "    # User vector\n",
    "    user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "    \n",
    "    # User's favorite course indices\n",
    "    user_fav_idx = np.argsort(-user_vec)\n",
    "    \n",
    "    # User's favorite courses\n",
    "    user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "    print(f\"Top {top_n} favorite courses:\")\n",
    "    print(user_fav)\n",
    "    \n",
    "    # Flatten pred_rating\n",
    "    pred_rating = np.asarray(pred_rating).flatten()\n",
    "    \n",
    "    \n",
    "    # Argsort the rating except the courses taken by the user\n",
    "    recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "    \n",
    "    # Recommend top courses\n",
    "    top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "    \n",
    "    print(f\"Top {top_n} recommended courses:\")\n",
    "    print(top_courses)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # RMSE between true & predicted\n",
    "    rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2))\n",
    "    print(f\"RMSE = {rmse}\")\n",
    "    \n",
    "    return top_courses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 favorite courses:\n",
      "['ENGLIS 220', 'EART 156', 'NATIVEA 310', 'EART 255', 'WG 211', 'ASIA 243', 'ASIA 244', 'MAT 216', 'ASIANLA 266', 'NATIVEA 422']\n",
      "Top 10 recommended courses:\n",
      "['EEC 183', 'EE 484', 'EEC 280', 'EE 483', 'MAT 295', 'MAT 403', 'MAT 296', 'MAT 286', 'MAT 327', 'MAT 297']\n",
      "\n",
      "RMSE = 4.873693740931147\n",
      "CPU times: user 1.02 s, sys: 444 ms, total: 1.46 s\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = memory_based(csr, -1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def nmf_based(uc_mat, user_idx, num_factors, top_n = 10, random_state=42):\n",
    "    # NMF based collaborative filtering\n",
    "    \n",
    "    # NMF\n",
    "    nmf = NMF(n_components = num_factors, init = 'nndsvd', max_iter = 300, random_state = random_state)\n",
    "    \n",
    "    # Transform X\n",
    "    X_transformed = nmf.fit_transform(uc_mat)\n",
    "    \n",
    "    # Calculate r\n",
    "    r = np.matmul(X_transformed, nmf.components_)\n",
    "    \n",
    "    # Predict rating\n",
    "    pred_rating = r[user_idx,:].reshape(1,-1)\n",
    "    \n",
    "    \n",
    "    # User vector\n",
    "    user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "    \n",
    "    # User's favorite course indices\n",
    "    user_fav_idx = np.argsort(-user_vec)\n",
    "    \n",
    "    # User's favorite courses\n",
    "    user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "    print(f\"Top {top_n} favorite courses:\")\n",
    "    print(user_fav)\n",
    "    \n",
    "    # Flatten pred_rating\n",
    "    pred_rating = np.asarray(pred_rating).flatten()\n",
    "    \n",
    "    \n",
    "    # Argsort the rating except the courses taken by the user\n",
    "    recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "    \n",
    "    # Recommend top courses\n",
    "    top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "    \n",
    "    print(f\"Top {top_n} recommended courses:\")\n",
    "    print(top_courses)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # RMSE between true & predicted\n",
    "    rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2))\n",
    "    print(f\"RMSE = {rmse}\")\n",
    "    \n",
    "    return top_courses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 favorite courses:\n",
      "['ENGLIS 220', 'EART 156', 'NATIVEA 310', 'EART 255', 'WG 211', 'ASIA 243', 'ASIA 244', 'MAT 216', 'ASIANLA 266', 'NATIVEA 422']\n",
      "Top 10 recommended courses:\n",
      "['EEC 183', 'LIN 393', 'EECS 487', 'EECS 482', 'EECS 581', 'EECS 491', 'EECS 574', 'RELIGIO 310', 'EECS 543', 'EECS 478']\n",
      "\n",
      "RMSE = 4.346884211155051\n",
      "CPU times: user 31.4 s, sys: 614 ms, total: 32.1 s\n",
      "Wall time: 35.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 300 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = nmf_based(csr, -1, 80, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
