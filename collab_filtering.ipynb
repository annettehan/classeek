{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update (12.13)\n",
    "### read_date(file_path)\n",
    "* input: file_path\n",
    "* output: \n",
    "     - csr: csr matrix of user profile data\n",
    "     - courses: list of courses\n",
    "     \n",
    "### memory_based(csr, courses, user_input, top_n = 10, random_state=42)\n",
    "* input: \n",
    "    - csr\n",
    "    - courses\n",
    "    - user_input\n",
    "    - csr, courses and the other inputs can be assigned inside the function. \n",
    "    \n",
    "* output:\n",
    "    - recommended courses\n",
    "    \n",
    "--------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and convert into sparse matrix\n",
    "\n",
    "### Update: read_data will take a file_path and output a csr and course list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    from scipy.sparse import csr_matrix\n",
    "    \n",
    "    # Read pickle\n",
    "    stu = pd.read_pickle(file_path)\n",
    "    \n",
    "    # Num of dictionaries in the file\n",
    "    n = len(stu)\n",
    "    \n",
    "    # Initialize df\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Loop through dicts and concat\n",
    "    for i in range(n):\n",
    "        stu[i]['student_id'] = i\n",
    "        df = pd.concat([df,stu[i]])\n",
    "    \n",
    "    # df = user dataset we have\n",
    "    # user_input: courses that user provide\n",
    "\n",
    "    # Fix .0 issues -- Some courses has .0 at the end (e.g. AAS 101.0), remove .0\n",
    "    df.loc[df['Subject/Catalog'].str.contains('\\.') == True, 'Subject/Catalog'] = df.loc[df['Subject/Catalog'].str.contains('\\.') == True, 'Subject/Catalog'].str.split('\\.').str[0]\n",
    "    \n",
    "    # Pivot table to stu - course\n",
    "    df = pd.pivot_table(df, values = 'Rating', index = 'student_id', columns = 'Subject/Catalog')\n",
    "    \n",
    "    # Fillna\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # df to sparse matrix\n",
    "    csr = csr_matrix(df)\n",
    "    \n",
    "    # Store course names\n",
    "    courses = list(df.columns)\n",
    "    \n",
    "\n",
    "    return csr, courses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csr, courses = read_data('student_profiles.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store user profile csr and the list of courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('csr.pkl', \"wb\") as fOut:\n",
    "    pickle.dump(csr, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('courses.pkl', \"wb\") as fOut:\n",
    "    pickle.dump(courses, fOut, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load csr and courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('csr.pkl', \"rb\") as fIn:\n",
    "    csr = pickle.load(fIn)\n",
    "with open('courses.pkl', \"rb\") as fIn:\n",
    "     courses = pickle.load(fIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random user input\n",
    "user_input = np.random.choice(courses, size = 10, replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def memory_based(csr, courses, user_input, top_n = 10):\n",
    "    # Memory-based collaborative filtering\n",
    "    user_idx = -1\n",
    "    \n",
    "    user_row = np.isin(courses, user_input)\n",
    "    uc_mat = vstack([csr, user_row]).tocsr()\n",
    "    # Normalize user-course matrix\n",
    "    norm_uc_mat = uc_mat - uc_mat.mean(axis = 1).reshape(-1,1)\n",
    "    \n",
    "    # Cosine similarity of raw matrix\n",
    "    cossim = cosine_similarity(uc_mat)\n",
    "    \n",
    "    # Calculate the numerator of V-hat(aj)\n",
    "    v_num = np.dot(cossim[user_idx,:], norm_uc_mat)\n",
    "    \n",
    "    # Sum of V-hat(aj) numerator\n",
    "    v_num_sum = v_num.sum(axis = 0)\n",
    "    \n",
    "    # V_hat(aj)\n",
    "    v_hat = v_num_sum/(cossim[user_idx,:].sum())\n",
    "    \n",
    "    #Predicted rating of each course\n",
    "    pred_rating = np.add(v_hat, uc_mat.mean(axis = 1).reshape(-1,1)[user_idx])\n",
    "    \n",
    "    # User vector\n",
    "    user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "    \n",
    "    # User's favorite course indices\n",
    "    user_fav_idx = np.argsort(-user_vec)\n",
    "    \n",
    "    # User's favorite courses\n",
    "    user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "    #print(f\"Top {top_n} favorite courses:\")\n",
    "    #print(user_fav)\n",
    "    \n",
    "    # Flatten pred_rating\n",
    "    pred_rating = np.asarray(pred_rating).flatten()\n",
    "    \n",
    "    \n",
    "    # Argsort the rating except the courses taken by the user\n",
    "    recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "    \n",
    "    # Recommend top courses\n",
    "    top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "    \n",
    "    #print(f\"Top {top_n} recommended courses:\")\n",
    "    #print(top_courses)\n",
    "\n",
    "    #print()\n",
    "\n",
    "    # RMSE between true & predicted\n",
    "    rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2))\n",
    "    #print(f\"RMSE = {rmse}\")\n",
    "    \n",
    "    return top_courses, rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['EECS 280',\n",
       "  'EECS 301',\n",
       "  'EEC 270',\n",
       "  'EEC 280',\n",
       "  'EEC 203',\n",
       "  'MAT 451',\n",
       "  'MAT 403',\n",
       "  'MAT 327',\n",
       "  'MAT 427',\n",
       "  'MAT 422'],\n",
       " 2.194925444737049)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = np.random.choice(courses, size = 10, replace = False)\n",
    "memory_based(csr, courses, user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
