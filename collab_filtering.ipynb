{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "### read_data(file_path)\n",
    "- read data to df\n",
    "\n",
    "### concat_user_input_and_convert_to_csr(df, user_input): \n",
    "- df: output df from read_data\n",
    "- user_input: list of courses the user provide\n",
    "- Append user input to the df and convert the df into csr. \n",
    "- Returns csr matrix, and course list.\n",
    "\n",
    "### svd_based(uc_mat, courses, user_idx = -1, num_factors=80, top_n = 10, random_state=42):\n",
    "- uc_mat: csr matrix (1st output of concat_user_input_and_convert_to_csr)\n",
    "- courses: course list (2nd output of concat_user_input_and_convert_to_csr)\n",
    "- num_factors: hyperparam of svd\n",
    "- top_n: num of recommendation\n",
    "- Returns top_n recommended courses\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook\n",
    "* Try three different collaborative filterings: Memory, SVD, NMF\n",
    "* Speed: SVD - Memory - NMF (fast to slow)\n",
    "* RMSE: SVD - NMF - Memory (low to high)\n",
    "\n",
    "\n",
    "* Winner: SVD\n",
    "\n",
    "## Note\n",
    "* Parameter tuning (SVD: num_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and convert into sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    from scipy.sparse import csr_matrix\n",
    "    \n",
    "    # Read pickle\n",
    "    stu = pd.read_pickle(file_path)\n",
    "    \n",
    "    # Num of dictionaries in the file\n",
    "    n = len(stu)\n",
    "    \n",
    "    # Initialize df\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Loop through dicts and concat\n",
    "    for i in range(n):\n",
    "        stu[i]['student_id'] = i\n",
    "        df = pd.concat([df,stu[i]])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def concat_user_input_and_convert_to_csr(df, user_input):\n",
    "    # df = user dataset we have\n",
    "    # user_input: courses that user provide\n",
    "\n",
    "    # User input to df and concat\n",
    "    user_df = pd.DataFrame()\n",
    "    user_df['Subject/Catalog'] = user_input\n",
    "    user_df['Rating'] = 1\n",
    "    user_df['student_id'] = df['student_id'].max()+1\n",
    "\n",
    "    df = pd.concat([df, user_df])\n",
    "    # Fix .0 issues -- Some courses has .0 at the end (e.g. AAS 101.0), remove .0\n",
    "    df.loc[df['Subject/Catalog'].str.contains('\\.') == True, 'Subject/Catalog'] = df.loc[df['Subject/Catalog'].str.contains('\\.') == True, 'Subject/Catalog'].str.split('\\.').str[0]\n",
    "    \n",
    "    # Pivot table to stu - course\n",
    "    df = pd.pivot_table(df, values = 'Rating', index = 'student_id', columns = 'Subject/Catalog')\n",
    "    \n",
    "    # Fillna\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # df to sparse matrix\n",
    "    csr = csr_matrix(df)\n",
    "    \n",
    "    # Store course names\n",
    "    courses = list(df.columns)\n",
    "    \n",
    "    # Get matched user by cos sim -- uncomment this if we use this information\n",
    "    #matched_user_idx = np.argsort(cosine_similarity(csr)[-1])[-2] #Best match of stu_idx -1 \n",
    "    \n",
    "    return csr, courses #matched_user_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject/Catalog</th>\n",
       "      <th>Course List Description</th>\n",
       "      <th>Credits</th>\n",
       "      <th>Course Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>student_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MATH 295</td>\n",
       "      <td>CS-LSA major declaration Cal I</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Honors Math I</td>\n",
       "      <td>4.021522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MATH 116</td>\n",
       "      <td>CS-LSA major declaration Cal II</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Calculus II</td>\n",
       "      <td>3.503458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IOE 265</td>\n",
       "      <td>Core Probability</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Prob&amp;Stat for Eng</td>\n",
       "      <td>2.513271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EECS 482</td>\n",
       "      <td>Upper Level CS Technical Electives (ULCS)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Intro Oper System</td>\n",
       "      <td>2.275309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EECS 590</td>\n",
       "      <td>Upper Level CS Technical Electives (ULCS)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Adv Prog Lang</td>\n",
       "      <td>2.329611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MEM 210</td>\n",
       "      <td>SS</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Early Med Europe</td>\n",
       "      <td>3.372078</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HISTOR 340</td>\n",
       "      <td>SS</td>\n",
       "      <td>4.0</td>\n",
       "      <td>From Genghis Khan to the Taliban:  Modern Cent...</td>\n",
       "      <td>3.164601</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HISTOR 394</td>\n",
       "      <td>HU</td>\n",
       "      <td>3.0</td>\n",
       "      <td>History of the Turkish Republic</td>\n",
       "      <td>3.941316</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AMCUL 392</td>\n",
       "      <td>HU</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mad, Bad, and Sad: Mental Health in the U.S.</td>\n",
       "      <td>3.627988</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HISTOR 200</td>\n",
       "      <td>HU</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Ancient Greece</td>\n",
       "      <td>2.885644</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160857 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject/Catalog                     Course List Description  Credits  \\\n",
       "0         MATH 295              CS-LSA major declaration Cal I      4.0   \n",
       "1         MATH 116             CS-LSA major declaration Cal II      4.0   \n",
       "2          IOE 265                            Core Probability      3.0   \n",
       "3         EECS 482  Upper Level CS Technical Electives (ULCS)       4.0   \n",
       "4         EECS 590  Upper Level CS Technical Electives (ULCS)       4.0   \n",
       "..             ...                                         ...      ...   \n",
       "28         MEM 210                                          SS      4.0   \n",
       "29      HISTOR 340                                          SS      4.0   \n",
       "30      HISTOR 394                                          HU      3.0   \n",
       "31       AMCUL 392                                          HU      3.0   \n",
       "32      HISTOR 200                                          HU      3.0   \n",
       "\n",
       "                                         Course Title    Rating  student_id  \n",
       "0                                       Honors Math I  4.021522           0  \n",
       "1                                         Calculus II  3.503458           0  \n",
       "2                                   Prob&Stat for Eng  2.513271           0  \n",
       "3                                   Intro Oper System  2.275309           0  \n",
       "4                                       Adv Prog Lang  2.329611           0  \n",
       "..                                                ...       ...         ...  \n",
       "28                                   Early Med Europe  3.372078        4999  \n",
       "29  From Genghis Khan to the Taliban:  Modern Cent...  3.164601        4999  \n",
       "30                    History of the Turkish Republic  3.941316        4999  \n",
       "31       Mad, Bad, and Sad: Mental Health in the U.S.  3.627988        4999  \n",
       "32                                     Ancient Greece  2.885644        4999  \n",
       "\n",
       "[160857 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_data('student_profiles.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcat = df['Subject/Catalog'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def svd_based(uc_mat, courses, num_factors=80, top_n = 10, random_state=42):\n",
    "    # SVD based collaborative filtering\n",
    "    \n",
    "    # user_idx = -1\n",
    "    user_idx = -1\n",
    "    \n",
    "    param_grid = {'n_components' : [60, 65, 70, 75, 80, 85]}\n",
    "    \n",
    "    # SVD\n",
    "    svd = TruncatedSVD(n_components = num_factors, random_state = random_state)\n",
    "    \n",
    "    # Transform X\n",
    "    X_transformed = svd.fit_transform(uc_mat)\n",
    "    \n",
    "    # Calculate r\n",
    "    r = np.matmul(X_transformed, svd.components_)\n",
    "    \n",
    "    # Pred rating\n",
    "    pred_rating = r[user_idx,:]#.reshape(1,-1)\n",
    "    \n",
    "    \n",
    "    # Matched user vector\n",
    "    user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "    \n",
    "    \n",
    "    # User's favorite course indices\n",
    "    user_fav_idx = np.argsort(-user_vec)\n",
    "    \n",
    "    # User's favorite courses\n",
    "    #user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "    #print(f\"Top {top_n} favorite courses:\")\n",
    "    #print(user_fav)\n",
    "\n",
    "    \n",
    "    # Flatten pred_rating\n",
    "    pred_rating = np.asarray(pred_rating).flatten()\n",
    "    \n",
    "    # Argsort the rating except the courses taken by the user\n",
    "    recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "    \n",
    "    # Recommend top courses\n",
    "    top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "    \n",
    "    print(f\"Top {top_n} recommended courses:\")\n",
    "    print(top_courses)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # RMSE between true & predicted. Uncomment the next two lines to see RMSE\n",
    "    rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2))\n",
    "    print(f\"RMSE = {rmse}\")\n",
    "    \n",
    "    return top_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommended courses:\n",
      "['EECS 581', 'EECS 385', 'EECS 482', 'RELIGIO 310', 'EECS 473', 'EECS 487', 'ENVIRO 167', 'EECS 490', 'EECS 280', 'SA 315']\n",
      "\n",
      "RMSE = 4.320117968276276\n",
      "CPU times: user 793 ms, sys: 117 ms, total: 911 ms\n",
      "Wall time: 418 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = svd_based(csr, courses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate avg RMSE of SVD with diff n_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcat = df['Subject/Catalog'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def svd_tune(df, num_factors, top_n = 10, random_state=42):\n",
    "    # SVD based collaborative filtering\n",
    "    \n",
    "    # user_idx = -1\n",
    "    user_idx = -1\n",
    "    rmse_list = []\n",
    "    for i in range(100):\n",
    "        user_input = np.random.choice(subcat, size = 10, replace = False)\n",
    "        uc_mat, courses = concat_user_input_and_convert_to_csr(df, user_input)\n",
    "\n",
    "        # SVD\n",
    "        svd = TruncatedSVD(n_components = num_factors, random_state = random_state)\n",
    "\n",
    "        # Transform X\n",
    "        X_transformed = svd.fit_transform(uc_mat)\n",
    "\n",
    "        # Calculate r\n",
    "        r = np.matmul(X_transformed, svd.components_)\n",
    "\n",
    "        # Pred rating\n",
    "        pred_rating = r[user_idx,:]#.reshape(1,-1)\n",
    "\n",
    "\n",
    "        # Matched user vector\n",
    "        user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "\n",
    "\n",
    "        # User's favorite course indices\n",
    "        user_fav_idx = np.argsort(-user_vec)\n",
    "\n",
    "        # User's favorite courses\n",
    "        #user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "        #print(f\"Top {top_n} favorite courses:\")\n",
    "        #print(user_fav)\n",
    "\n",
    "\n",
    "        # Flatten pred_rating\n",
    "        pred_rating = np.asarray(pred_rating).flatten()\n",
    "\n",
    "        # Argsort the rating except the courses taken by the user\n",
    "        recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "\n",
    "        # Recommend top courses\n",
    "        top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "\n",
    "\n",
    "        # RMSE between true & predicted. Uncomment the next two lines to see RMSE\n",
    "        rmse_list.append(np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2)))\n",
    "    avg_rmse = np.average(rmse_list)\n",
    "    #print(f\"RMSE = {avg_rmse}\")\n",
    "    \n",
    "    return avg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 4.364242197081958\n",
      "RMSE = 4.357827404798507\n",
      "RMSE = 4.359784457612434\n",
      "RMSE = 4.346068447475665\n",
      "RMSE = 4.337082405850965\n",
      "RMSE = 4.330620854141026\n",
      "RMSE = 4.320117968276278\n",
      "RMSE = 4.324448355403818\n",
      "RMSE = 4.30260091539495\n"
     ]
    }
   ],
   "source": [
    "avg_rmse_list = []\n",
    "for num in [50, 55, 60, 65, 70, 75, 80, 85, 90]:\n",
    "    avg_rmse = svd_tune(df, num, top_n = 10, random_state=42)\n",
    "    avg_rmse_list.append(avg_rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/anaconda3/lib/python3.8/site-packages (from bayesian-optimization) (1.21.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /opt/anaconda3/lib/python3.8/site-packages (from bayesian-optimization) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /opt/anaconda3/lib/python3.8/site-packages (from bayesian-optimization) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.17.0)\n",
      "Building wheels for collected packages: bayesian-optimization\n",
      "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11685 sha256=66c6540c73156f630062a7533f31207b79a0e40505d64949e6d2badf702820a3\n",
      "  Stored in directory: /Users/Yeseul/Library/Caches/pip/wheels/37/fa/19/f93e793d3944567a60b3ab93b446cf7370cc82c60c1d1c613f\n",
      "Successfully built bayesian-optimization\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "def BO_func(n_components):\n",
    "    avg_rmse = svd_tune(df, int(n_components), top_n = 10, random_state=42)\n",
    "    return -avg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | n_comp... |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-3.087   \u001b[0m | \u001b[0m 118.7   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-3.061   \u001b[0m | \u001b[95m 147.5   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-3.087   \u001b[0m | \u001b[0m 136.6   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-3.083   \u001b[0m | \u001b[0m 129.9   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-3.067   \u001b[0m | \u001b[0m 146.6   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-3.083   \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-3.068   \u001b[0m | \u001b[0m 144.2   \u001b[0m |\n",
      "=====================================\n",
      "CPU times: user 32min 52s, sys: 5min 50s, total: 38min 42s\n",
      "Wall time: 31min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tuning_params = { \n",
    "  \"n_components\": (100, 150) }\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "  f = BO_func,\n",
    "  pbounds = tuning_params,\n",
    "  verbose = 5,\n",
    "  random_state = 42\n",
    " )\n",
    "\n",
    "optimizer.maximize(\n",
    "  init_points = 4,\n",
    "  n_iter = 3 \n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | n_comp... |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-3.024   \u001b[0m | \u001b[0m 218.5   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.86    \u001b[0m | \u001b[95m 477.8   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.903   \u001b[0m | \u001b[0m 379.4   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.96    \u001b[0m | \u001b[0m 319.4   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-2.848   \u001b[0m | \u001b[95m 500.0   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-2.814   \u001b[0m | \u001b[95m 498.8   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.849   \u001b[0m | \u001b[0m 494.9   \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "tuning_params = { \n",
    "  \"n_components\": (50, 500) }\n",
    "\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "  f = BO_func,\n",
    "  pbounds = tuning_params,\n",
    "  verbose = 5,\n",
    "  random_state = 42\n",
    " )\n",
    "\n",
    "optimizer.maximize(\n",
    "  init_points = 4,\n",
    "  n_iter = 3 \n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "uc_mat = csr\n",
    "\n",
    "def memory_based(uc_mat, user_idx, top_n):\n",
    "    # Memory-based collaborative filtering\n",
    "    \n",
    "    # Normalize user-course matrix\n",
    "    norm_uc_mat = uc_mat - uc_mat.mean(axis = 1).reshape(-1,1)\n",
    "    \n",
    "    # Cosine similarity of raw matrix\n",
    "    cossim = cosine_similarity(uc_mat)\n",
    "    \n",
    "    # Calculate the numerator of V-hat(aj)\n",
    "    v_num = np.dot(cossim[user_idx,:], norm_uc_mat)\n",
    "    \n",
    "    # Sum of V-hat(aj) numerator\n",
    "    v_num_sum = v_num.sum(axis = 0)\n",
    "    \n",
    "    # V_hat(aj)\n",
    "    v_hat = v_num_sum/(cossim[user_idx,:].sum())\n",
    "    \n",
    "    #Predicted rating of each course\n",
    "    pred_rating = np.add(v_hat, uc_mat.mean(axis = 1).reshape(-1,1)[user_idx])\n",
    "    \n",
    "    # User vector\n",
    "    user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "    \n",
    "    # User's favorite course indices\n",
    "    user_fav_idx = np.argsort(-user_vec)\n",
    "    \n",
    "    # User's favorite courses\n",
    "    user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "    print(f\"Top {top_n} favorite courses:\")\n",
    "    print(user_fav)\n",
    "    \n",
    "    # Flatten pred_rating\n",
    "    pred_rating = np.asarray(pred_rating).flatten()\n",
    "    \n",
    "    \n",
    "    # Argsort the rating except the courses taken by the user\n",
    "    recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "    \n",
    "    # Recommend top courses\n",
    "    top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "    \n",
    "    print(f\"Top {top_n} recommended courses:\")\n",
    "    print(top_courses)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # RMSE between true & predicted\n",
    "    rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2))\n",
    "    print(f\"RMSE = {rmse}\")\n",
    "    \n",
    "    return top_courses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 favorite courses:\n",
      "['ENGLIS 220', 'EART 156', 'NATIVEA 310', 'EART 255', 'WG 211', 'ASIA 243', 'ASIA 244', 'MAT 216', 'ASIANLA 266', 'NATIVEA 422']\n",
      "Top 10 recommended courses:\n",
      "['EEC 183', 'EE 484', 'EEC 280', 'EE 483', 'MAT 295', 'MAT 403', 'MAT 296', 'MAT 286', 'MAT 327', 'MAT 297']\n",
      "\n",
      "RMSE = 4.873693740931147\n",
      "CPU times: user 1.02 s, sys: 444 ms, total: 1.46 s\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = memory_based(csr, -1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def nmf_based(uc_mat, user_idx, num_factors, top_n = 10, random_state=42):\n",
    "    # NMF based collaborative filtering\n",
    "    \n",
    "    # NMF\n",
    "    nmf = NMF(n_components = num_factors, init = 'nndsvd', max_iter = 300, random_state = random_state)\n",
    "    \n",
    "    # Transform X\n",
    "    X_transformed = nmf.fit_transform(uc_mat)\n",
    "    \n",
    "    # Calculate r\n",
    "    r = np.matmul(X_transformed, nmf.components_)\n",
    "    \n",
    "    # Predict rating\n",
    "    pred_rating = r[user_idx,:].reshape(1,-1)\n",
    "    \n",
    "    \n",
    "    # User vector\n",
    "    user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "    \n",
    "    # User's favorite course indices\n",
    "    user_fav_idx = np.argsort(-user_vec)\n",
    "    \n",
    "    # User's favorite courses\n",
    "    user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "    print(f\"Top {top_n} favorite courses:\")\n",
    "    print(user_fav)\n",
    "    \n",
    "    # Flatten pred_rating\n",
    "    pred_rating = np.asarray(pred_rating).flatten()\n",
    "    \n",
    "    \n",
    "    # Argsort the rating except the courses taken by the user\n",
    "    recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "    \n",
    "    # Recommend top courses\n",
    "    top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "    \n",
    "    print(f\"Top {top_n} recommended courses:\")\n",
    "    print(top_courses)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # RMSE between true & predicted\n",
    "    rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2))\n",
    "    print(f\"RMSE = {rmse}\")\n",
    "    \n",
    "    return top_courses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 favorite courses:\n",
      "['ENGLIS 220', 'EART 156', 'NATIVEA 310', 'EART 255', 'WG 211', 'ASIA 243', 'ASIA 244', 'MAT 216', 'ASIANLA 266', 'NATIVEA 422']\n",
      "Top 10 recommended courses:\n",
      "['EEC 183', 'LIN 393', 'EECS 487', 'EECS 482', 'EECS 581', 'EECS 491', 'EECS 574', 'RELIGIO 310', 'EECS 543', 'EECS 478']\n",
      "\n",
      "RMSE = 4.346884211155051\n",
      "CPU times: user 31.4 s, sys: 614 ms, total: 32.1 s\n",
      "Wall time: 35.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 300 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = nmf_based(csr, -1, 80, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
