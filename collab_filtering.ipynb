{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook\n",
    "* Try three different collaborative filterings: Memory, SVD, NMF\n",
    "* Speed: SVD - Memory - NMF (fast to slow)\n",
    "* RMSE: SVD - NMF - Memory (low to high)\n",
    "\n",
    "\n",
    "* Winner: SVD\n",
    "\n",
    "## Note\n",
    "* Parameter tuning (SVD: num_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and convert into sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_csr(file_path):\n",
    "    from scipy.sparse import csr_matrix\n",
    "    \n",
    "    # Read pickle\n",
    "    stu = pd.read_pickle(file_path)\n",
    "    \n",
    "    # Num of dictionaries in the file\n",
    "    n = len(stu)\n",
    "    \n",
    "    # Initialize df\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Loop through dicts and concat\n",
    "    for i in range(n):\n",
    "        stu[i]['student_id'] = i\n",
    "        df = pd.concat([df,stu[i]])\n",
    "    \n",
    "    # Fix .0 issues -- Some courses has .0 at the end (e.g. AAS 101.0), remove .0\n",
    "    df.loc[df['Subject/Catalog'].str.contains('\\.') == True, 'Subject/Catalog'] = df.loc[df['Subject/Catalog'].str.contains('\\.') == True, 'Subject/Catalog'].str.split('\\.').str[0]\n",
    "    \n",
    "    # Pivot table to stu - course\n",
    "    df = pd.pivot_table(df, values = 'Rating', index = 'student_id', columns = 'Subject/Catalog')\n",
    "    \n",
    "    # Fillna\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # df to sparse matrix\n",
    "    csr = csr_matrix(df)\n",
    "    \n",
    "    # Store course names\n",
    "    courses = list(df.columns)\n",
    "    \n",
    "    return csr, courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr, courses = data_to_csr('student_profiles.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "uc_mat = csr\n",
    "user_idx = 0\n",
    "\n",
    "def memory_based(uc_mat, user_idx, top_n):\n",
    "    # Memory-based collaborative filtering\n",
    "    \n",
    "    # Normalize user-course matrix\n",
    "    norm_uc_mat = uc_mat - uc_mat.mean(axis = 1).reshape(-1,1)\n",
    "    \n",
    "    # Cosine similarity of raw matrix\n",
    "    cossim = cosine_similarity(uc_mat)\n",
    "    \n",
    "    # Calculate the numerator of V-hat(aj)\n",
    "    v_num = np.dot(cossim[user_idx,:], norm_uc_mat)\n",
    "    \n",
    "    # Sum of V-hat(aj) numerator\n",
    "    v_num_sum = v_num.sum(axis = 0)\n",
    "    \n",
    "    # V_hat(aj)\n",
    "    v_hat = v_num_sum/(cossim[user_idx,:].sum())\n",
    "    \n",
    "    #Predicted rating of each course\n",
    "    pred_rating = np.add(v_hat, uc_mat.mean(axis = 1).reshape(-1,1)[user_idx])\n",
    "    \n",
    "    # User vector\n",
    "    user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "    \n",
    "    # User's favorite course indices\n",
    "    user_fav_idx = np.argsort(-user_vec)\n",
    "    \n",
    "    # User's favorite courses\n",
    "    user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "    print(f\"Top {top_n} favorite courses:\")\n",
    "    print(user_fav)\n",
    "    \n",
    "    # Flatten pred_rating\n",
    "    pred_rating = np.asarray(pred_rating).flatten()\n",
    "    \n",
    "    \n",
    "    # Argsort the rating except the courses taken by the user\n",
    "    recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "    \n",
    "    # Recommend top courses\n",
    "    top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "    \n",
    "    print(f\"Top {top_n} recommended courses:\")\n",
    "    print(top_courses)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # RMSE between true & predicted\n",
    "    rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2))\n",
    "    print(f\"RMSE = {rmse}\")\n",
    "    \n",
    "    return top_courses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 favorite courses:\n",
      "['EECS 370', 'ENSCE 105', 'EECS 443', 'EECS 280', 'EECS 203', 'SPANIS 373', 'ECO 497', 'CHE 211', 'RCAS 202', 'ENGLIS 387']\n",
      "Top 10 recommended courses:\n",
      "['MAT 175', 'MAT 205', 'MAT 186', 'MAT 174', 'MAT 176', 'MAT 185', 'EECS 367', 'EECS 280', 'EECS 385', 'EECS 481']\n",
      "\n",
      "RMSE = 18.227582054884557\n",
      "CPU times: user 822 ms, sys: 374 ms, total: 1.2 s\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = memory_based(csr, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def svd_based(uc_mat, user_idx, num_factors, top_n = 10, random_state=42):\n",
    "    # SVD based collaborative filtering\n",
    "    \n",
    "    # SVD\n",
    "    svd = TruncatedSVD(n_components = num_factors, random_state = random_state)\n",
    "    \n",
    "    # Transform X\n",
    "    X_transformed = svd.fit_transform(uc_mat)\n",
    "    \n",
    "    # Calculate r\n",
    "    r = np.matmul(X_transformed, svd.components_)\n",
    "    \n",
    "    # Pred rating\n",
    "    pred_rating = r[user_idx,:]#.reshape(1,-1)\n",
    "    \n",
    "    \n",
    "    # User vector\n",
    "    user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "    \n",
    "    # User's favorite course indices\n",
    "    user_fav_idx = np.argsort(-user_vec)\n",
    "    \n",
    "    # User's favorite courses\n",
    "    user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "    print(f\"Top {top_n} favorite courses:\")\n",
    "    print(user_fav)\n",
    "    \n",
    "    # Flatten pred_rating\n",
    "    pred_rating = np.asarray(pred_rating).flatten()\n",
    "    \n",
    "    # Argsort the rating except the courses taken by the user\n",
    "    recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "    \n",
    "    # Recommend top courses\n",
    "    top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "    \n",
    "    print(f\"Top {top_n} recommended courses:\")\n",
    "    print(top_courses)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # RMSE between true & predicted\n",
    "    rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2))\n",
    "    print(f\"RMSE = {rmse}\")\n",
    "    \n",
    "    return top_courses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 favorite courses:\n",
      "['EECS 370', 'ENSCE 105', 'EECS 443', 'EECS 280', 'EECS 203', 'SPANIS 373', 'ECO 497', 'CHE 211', 'RCAS 202', 'ENGLIS 387']\n",
      "Top 10 recommended courses:\n",
      "['RELIGIO 231', 'EEC 481', 'EECS 582', 'SA 140', 'EECS 571', 'EECS 489', 'EECS 203', 'HJC 335', 'EECS 492', 'LIN 347']\n",
      "\n",
      "RMSE = 15.867938151779919\n",
      "CPU times: user 938 ms, sys: 161 ms, total: 1.1 s\n",
      "Wall time: 553 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = svd_based(csr, 0, 80, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def nmf_based(uc_mat, user_idx, num_factors, top_n = 10, random_state=42):\n",
    "    # NMF based collaborative filtering\n",
    "    \n",
    "    # NMF\n",
    "    nmf = NMF(n_components = num_factors, init = 'nndsvd', max_iter = 300, random_state = random_state)\n",
    "    \n",
    "    # Transform X\n",
    "    X_transformed = nmf.fit_transform(uc_mat)\n",
    "    \n",
    "    # Calculate r\n",
    "    r = np.matmul(X_transformed, nmf.components_)\n",
    "    \n",
    "    # Predict rating\n",
    "    pred_rating = r[user_idx,:].reshape(1,-1)\n",
    "    \n",
    "    \n",
    "    # User vector\n",
    "    user_vec = uc_mat[user_idx].toarray().flatten()\n",
    "    \n",
    "    # User's favorite course indices\n",
    "    user_fav_idx = np.argsort(-user_vec)\n",
    "    \n",
    "    # User's favorite courses\n",
    "    user_fav = [courses[i] for i in user_fav_idx[:top_n]]\n",
    "    print(f\"Top {top_n} favorite courses:\")\n",
    "    print(user_fav)\n",
    "    \n",
    "    # Flatten pred_rating\n",
    "    pred_rating = np.asarray(pred_rating).flatten()\n",
    "    \n",
    "    \n",
    "    # Argsort the rating except the courses taken by the user\n",
    "    recommend_index = np.argsort(-pred_rating[user_vec == 0])\n",
    "    \n",
    "    # Recommend top courses\n",
    "    top_courses = [courses[i] for i in recommend_index[:top_n]]\n",
    "    \n",
    "    print(f\"Top {top_n} recommended courses:\")\n",
    "    print(top_courses)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # RMSE between true & predicted\n",
    "    rmse = np.sqrt(np.sum((user_vec[user_vec != 0] - pred_rating[user_vec != 0]) ** 2))\n",
    "    print(f\"RMSE = {rmse}\")\n",
    "    \n",
    "    return top_courses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 favorite courses:\n",
      "['EECS 370', 'ENSCE 105', 'EECS 443', 'EECS 280', 'EECS 203', 'SPANIS 373', 'ECO 497', 'CHE 211', 'RCAS 202', 'ENGLIS 387']\n",
      "Top 10 recommended courses:\n",
      "['MAT 175', 'EECS 281', 'SPANIS 473', 'SPANIS 485', 'TCHNCLC 380', 'EEC 203', 'SPANIS 476', 'ECO 494', 'EECS 582', 'SA 140']\n",
      "\n",
      "RMSE = 16.13685123447898\n",
      "CPU times: user 32.4 s, sys: 705 ms, total: 33.1 s\n",
      "Wall time: 36 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 300 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = nmf_based(csr, 0, 80, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
