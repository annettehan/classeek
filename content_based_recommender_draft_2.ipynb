{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook:\n",
    "- Recommend a course based on the course description\n",
    "1.    \n",
    "    - Topic modeling on course descriptions\n",
    "    - Take a course title (e.g. AAS 103)\n",
    "    - Take the course description of this course\n",
    "    - Process text of the description\n",
    "    - Find the topics of this block of text\n",
    "    \n",
    "2.    \n",
    "    - Process text of the descriptions of all other courses\n",
    "    - Find the topics of those blocks of text\n",
    "    \n",
    "3.    \n",
    "    - Match the topic of the input course and other courses\n",
    "    - Compute similarity scores\n",
    "    - Rank these scores from high to low\n",
    "    - Return the n number of recommendations needed (num_of_rec) by order of similarity\n",
    "    \n",
    "- Need to improve\n",
    "\n",
    "    - Text processing\n",
    "    - Topic modeling (the recommendations are not quite logical yet since the text processing and topic modeling are not quite well-done yet)\n",
    "    - Efficiency of the algorithm (slow now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update\n",
    "1. Because the courses already have distinct clusters such as academic groups (LSI, engineering, dentistry ...) and subject (Afroamerican sections, etc), it makes more sense that we recommend courses in the same academic group and subject.\n",
    "\n",
    "\n",
    "2. Somehow, processing the texts (stopwords removal, lemma, etc) produce poorer recommendations. The results look much better without the language processing. \n",
    "\n",
    "\n",
    "3. About topic modeling -- I'm not sure how we could utilize topic modeling, since the total number of academic group is about 20 so if we cluster the courses with topic modeling, it's not going to work very well unless we use a large number of cluster like 200 - 500. We could try topic modeling in the subject level, but I think count vec and tfidf vec works pretty well, so not sure if that would be necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "- Concat fall and winter -> add \"semester\" parameter (fall, winter, doesn't matter)\n",
    "- Add LSA requirement parameter\n",
    "\n",
    "- Maybe we also want to add filter level None\n",
    "- I think we should add an option to recommenda a Michigan online course based on the content of the entered course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper that helps: https://www.frontiersin.org/articles/10.3389/frai.2020.00042/full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import neattext.functions as nfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel, sigmoid_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load our dataset\n",
    "# f_21 = pd.read_csv('assets/f_21_merge.csv')\n",
    "# w_22 = pd.read_csv('assets/w_22_merge.csv')\n",
    "\n",
    "# df = pd.concat([f_21, w_22])\n",
    "\n",
    "# df.columns\n",
    "\n",
    "# df = df.fillna('')\n",
    "# df['requirements_distribution'] = df['requirements_distribution'] + ', ' + df['other']\n",
    "# df['requirements_distribution'] = [x.split(', ') for x in df['requirements_distribution']]\n",
    "\n",
    "# df['text'] = df['Course Title'] + df['sub_title'] + df['description'] + df['Acad Group'] + df['Subject']\n",
    "\n",
    "# df.drop_duplicates(subset='course', inplace=True)\n",
    "\n",
    "# df.to_csv('assets/fw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters:\n",
    "\n",
    "* df = input dataset\n",
    "* course_title = input course\n",
    "* num_or_rec = number of recommendation\n",
    "* filter_level = 'academic_group', subject', or 'no_filter'\n",
    "* semester = 'fall' or 'winter'\n",
    "* lsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid options for drop-down selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course title: free text of similar format -- still thinking about whether to make it free text or only valid options\n",
    "\n",
    "# Num of rec: 1<n<10, otherwise: invalid\n",
    "\n",
    "# filter_level\n",
    "filter_level_options = ['academic_group', 'subject']\n",
    "\n",
    "# semester\n",
    "semester_options = df['Term'].unique().tolist()\n",
    "\n",
    "# lsa\n",
    "lsa_list = {x for l in df['requirements_distribution'].dropna() for x in l}\n",
    "lsa_options = [i for i in lsa_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendation_cos(course_title, num_of_rec=10, filter_level='subject', semester='Fall 2021', lsa=None):\n",
    "    \n",
    "    if int(num_of_rec) > 10 or int(num_of_rec) < 1:\n",
    "        print('Please enter the desire number of recommendation between 1 and 10 (inclusive).')\n",
    "        \n",
    "    else:\n",
    "        # Read csv\n",
    "        df = pd.read_csv('assets/fw.csv')\n",
    "\n",
    "        # Specify valid courses\n",
    "        valid_courses = df['course'].unique().tolist()\n",
    "\n",
    "        if course_title not in valid_courses:\n",
    "            print(f'Please enter a valid course choice. Course {course_title} is not in our list.')\n",
    "\n",
    "        else:\n",
    "            # Specify semester\n",
    "            df = df[df['Term'] == semester]\n",
    "\n",
    "            # Input \n",
    "            input_ag = df.loc[df['course'] == course_title, 'Acad Group']\n",
    "            input_sub = df.loc[df['course'] == course_title, 'Subject']\n",
    "            input_course = df.loc[df['course'] == course_title, 'Course Title']\n",
    "\n",
    "            # Filter the df\n",
    "            if filter_level == 'academic_group':\n",
    "                df = df[df['Acad Group'].isin(input_ag)] \n",
    "            elif filter_level == 'subject':\n",
    "                df = df[(df['Subject'].isin(input_sub)) | (df['Course Title'].isin(input_course))]\n",
    "            \n",
    "            if len(df) == 0:\n",
    "                print('Sorry, there is no match. Please try again with a different course or choose a different LSA requirement distribution.')\n",
    "                \n",
    "            else:\n",
    "                # Reset index\n",
    "                df.reset_index(inplace=True)\n",
    "\n",
    "                # Vectorize our Text\n",
    "                count_vect = CountVectorizer()\n",
    "                cv_mat = count_vect.fit_transform(df['text'])\n",
    "\n",
    "                # Cosine Similarity Matrix\n",
    "                cosine_sim_mat = cosine_similarity(cv_mat)\n",
    "\n",
    "                # Get Course ID/Index\n",
    "                course_indices = pd.Series(df.index, index=df['course'])\n",
    "\n",
    "                # ID for title\n",
    "                idx = course_indices[course_title]\n",
    "\n",
    "                # Course Indice\n",
    "                # Search inside cosine_sim_mat\n",
    "                scores = list(enumerate(cosine_sim_mat[idx]))\n",
    "\n",
    "                # Scores\n",
    "                # Sort Scores\n",
    "                sorted_scores = sorted(scores, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "                # Recommender\n",
    "                selected_course_indices = [i[0] for i in sorted_scores[1:]]\n",
    "                selected_course_scores = [i[1] for i in sorted_scores[1:]]\n",
    "\n",
    "                result = df[df.columns].iloc[selected_course_indices]\n",
    "\n",
    "                rec_df = pd.DataFrame(result)\n",
    "\n",
    "                rec_df['similarity_scores'] = selected_course_scores\n",
    "\n",
    "                # Filter by lsa requirement distribution\n",
    "                if lsa == None:\n",
    "                    rec_df = rec_df\n",
    "                else:\n",
    "                    rec_df = rec_df[rec_df['requirements_distribution'].map(lambda x: lsa in x)]\n",
    "\n",
    "                # If query returns no results, return error message, otherwise, return df filtered to these colummsn\n",
    "                \n",
    "                cols_to_filter = ['course', 'Term', 'Acad Group', 'Subject', 'Course Title', 'description', 'credits', 'requirements_distribution', 'similarity_scores']\n",
    "                \n",
    "                if len(rec_df) == 0:\n",
    "                    print('Sorry, there is no match. Please try again with a different course or choose a different LSA requirement distribution.')\n",
    "                \n",
    "                elif len(rec_df) < num_of_rec:\n",
    "                    rec_df = rec_df[cols_to_filter]\n",
    "                    return rec_df\n",
    "                    \n",
    "                else:\n",
    "                    rec_df = rec_df[:num_of_rec][cols_to_filter]\n",
    "                    return rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>Term</th>\n",
       "      <th>Acad Group</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Course Title</th>\n",
       "      <th>description</th>\n",
       "      <th>credits</th>\n",
       "      <th>requirements_distribution</th>\n",
       "      <th>similarity_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMCULT 371</td>\n",
       "      <td>Fall 2021</td>\n",
       "      <td>Literature, Sci, and the Arts</td>\n",
       "      <td>American Culture (AMCULT) Open Sections</td>\n",
       "      <td>Sex &amp; Gender US Hist</td>\n",
       "      <td>Beginning in seventeenth-century British Ameri...</td>\n",
       "      <td>3</td>\n",
       "      <td>['HU', 'RE', '']</td>\n",
       "      <td>0.990550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>WGS 371</td>\n",
       "      <td>Fall 2021</td>\n",
       "      <td>Literature, Sci, and the Arts</td>\n",
       "      <td>Women's and Gender Studies (WGS) Open Sections</td>\n",
       "      <td>Sex &amp; Gender US Hist</td>\n",
       "      <td>Beginning in seventeenth-century British Ameri...</td>\n",
       "      <td>3</td>\n",
       "      <td>['HU', 'RE', '']</td>\n",
       "      <td>0.988558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HISTORY 346</td>\n",
       "      <td>Fall 2021</td>\n",
       "      <td>Literature, Sci, and the Arts</td>\n",
       "      <td>History (HISTORY) Open Sections</td>\n",
       "      <td>American Radicalism</td>\n",
       "      <td>This course offers a general history of radica...</td>\n",
       "      <td>4</td>\n",
       "      <td>['SS', '']</td>\n",
       "      <td>0.742455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>HISTORY 450</td>\n",
       "      <td>Fall 2021</td>\n",
       "      <td>Literature, Sci, and the Arts</td>\n",
       "      <td>History (HISTORY) Open Sections</td>\n",
       "      <td>Japan to 1700</td>\n",
       "      <td>What lies behind the image of “Cool Japan,” re...</td>\n",
       "      <td>3</td>\n",
       "      <td>['', '']</td>\n",
       "      <td>0.736586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HISTORY 312</td>\n",
       "      <td>Fall 2021</td>\n",
       "      <td>Literature, Sci, and the Arts</td>\n",
       "      <td>History (HISTORY) Open Sections</td>\n",
       "      <td>European Integration</td>\n",
       "      <td>The construction of the European Union has bee...</td>\n",
       "      <td>4</td>\n",
       "      <td>['ID', '']</td>\n",
       "      <td>0.733807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         course       Term                     Acad Group  \\\n",
       "0    AMCULT 371  Fall 2021  Literature, Sci, and the Arts   \n",
       "73      WGS 371  Fall 2021  Literature, Sci, and the Arts   \n",
       "24  HISTORY 346  Fall 2021  Literature, Sci, and the Arts   \n",
       "45  HISTORY 450  Fall 2021  Literature, Sci, and the Arts   \n",
       "19  HISTORY 312  Fall 2021  Literature, Sci, and the Arts   \n",
       "\n",
       "                                           Subject          Course Title  \\\n",
       "0          American Culture (AMCULT) Open Sections  Sex & Gender US Hist   \n",
       "73  Women's and Gender Studies (WGS) Open Sections  Sex & Gender US Hist   \n",
       "24                 History (HISTORY) Open Sections   American Radicalism   \n",
       "45                 History (HISTORY) Open Sections         Japan to 1700   \n",
       "19                 History (HISTORY) Open Sections  European Integration   \n",
       "\n",
       "                                          description credits  \\\n",
       "0   Beginning in seventeenth-century British Ameri...       3   \n",
       "73  Beginning in seventeenth-century British Ameri...       3   \n",
       "24  This course offers a general history of radica...       4   \n",
       "45  What lies behind the image of “Cool Japan,” re...       3   \n",
       "19  The construction of the European Union has bee...       4   \n",
       "\n",
       "   requirements_distribution  similarity_scores  \n",
       "0           ['HU', 'RE', '']           0.990550  \n",
       "73          ['HU', 'RE', '']           0.988558  \n",
       "24                ['SS', '']           0.742455  \n",
       "45                  ['', '']           0.736586  \n",
       "19                ['ID', '']           0.733807  "
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_recommendation_cos('HISTORY 371', num_of_rec=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7329     POLSCI 630\n",
       "2173    HISTORY 371\n",
       "4298    STDABRD 340\n",
       "Name: course, dtype: object"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['course'].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'DATASCI 606'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendation_sk(df, course_title, num_of_rec = 10, filter_level = 'academic_group', semester = 'fall', lsa = None):\n",
    "    # Specify semester\n",
    "    df = df[df['semester'] == semester]\n",
    "    \n",
    "    # Clean df\n",
    "    df = df.fillna('').drop_duplicates(subset=['course']).reset_index().drop(columns='index')\n",
    "    \n",
    "    # Input \n",
    "    input_ag = df.loc[df['course'] == course_title, 'Acad Group'].unique()\n",
    "    input_sub = df.loc[df['course'] == course_title, 'Subject'].unique()\n",
    "    input_course = df.loc[df['course'] == course_title, 'Course Title'].unique()\n",
    "    \n",
    "    # Filter the df\n",
    "    if filter_level == 'academic_group':\n",
    "        df = df[df['Acad Group'].isin(input_ag)] \n",
    "    elif filter_level == 'subject':\n",
    "        df = df[(df['Subject'].isin(input_sub)) | (df['Course Title'].isin(input_course))]\n",
    "\n",
    "    # Merge all the text information\n",
    "    df['text'] = df['Acad Group'] + ' ' + df['Subject'] + ' ' + df['Course Title'] + ' ' + df['sub_title'] + ' ' + df['description']\n",
    "\n",
    "    # Reset index\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    # Vectorize our Text\n",
    "    tfidf = TfidfVectorizer(max_df = 0.5, max_features=None, \n",
    "                strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "                ngram_range=(1,1))\n",
    "\n",
    "    # Fitting the TF-IDF on the 'description' text\n",
    "    tfidf_matrix = tfidf.fit_transform(df['text'])\n",
    "\n",
    "    # Compute the sigmoid kernel\n",
    "    sig = sigmoid_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    # Reverse mapping of indices and course titles\n",
    "    indices = pd.Series(df.index, index=df['course']).drop_duplicates()\n",
    "\n",
    "    # Get the index corresponding to course title\n",
    "    idx = indices[course_title]\n",
    "\n",
    "    # Get the pairwise similarity scores \n",
    "    sig_scores = list(enumerate(sig[idx]))\n",
    "\n",
    "    # Sort the courses\n",
    "    sig_scores = sorted(sig_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Scores of the n most similar courses\n",
    "    sig_scores = sig_scores[1:num_of_rec+1]\n",
    "\n",
    "    # Take the indices\n",
    "    course_indices = [i[0] for i in sig_scores]\n",
    "\n",
    "    # Top 10 most similar courses\n",
    "    rec_df = df[df.columns].iloc[course_indices]\n",
    "    \n",
    "    rec_df['sig_scores'] = sig_scores\n",
    "\n",
    "    return rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_recommendation_sk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-ce57728c51b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_recommendation_sk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ECON 208'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'make_recommendation_sk' is not defined"
     ]
    }
   ],
   "source": [
    "make_recommendation_sk(f_21, 'ECON 208', 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
