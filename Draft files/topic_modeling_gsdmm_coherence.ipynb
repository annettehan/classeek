{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook:\n",
    "* Calculate topic coherence of gsdmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import neattext.functions as nfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_lda.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#spacy\n",
    "import spacy\n",
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#vis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install git+https://github.com/rwalk/gsdmm.git ## install gsdmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsdmm import MovieGroupProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "online = pd.read_csv('assets/original/2021-10-19-MichiganOnline-courses.csv')\n",
    "f_21 = pd.read_csv('assets/f_21_merge.csv')\n",
    "w_22 = pd.read_csv('assets/w_22_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(df):\n",
    "\n",
    "    data = df['description'].dropna()\n",
    "\n",
    "\n",
    "    def lemmatization(texts, allowed_postags=[\"NOUN\"]): #trying only noun instead [\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]\n",
    "        nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "        texts_out = []\n",
    "        for text in texts:\n",
    "            doc = nlp(text)\n",
    "            new_text = []\n",
    "            for token in doc:\n",
    "                if token.pos_ in allowed_postags:\n",
    "                    new_text.append(token.lemma_)\n",
    "            #final = \" \".join(new_text)\n",
    "            texts_out.append(new_text)\n",
    "        return (texts_out)\n",
    "\n",
    "    lemmatized_texts = lemmatization(data)\n",
    "\n",
    "    def stop_word_removal(texts):\n",
    "\n",
    "        flat_texts = [t for text in texts for t in text]\n",
    "        common_words = [k for k,v in Counter(flat_texts).most_common(10)]\n",
    "        texts_out = []\n",
    "        stop = set(stopwords.words('english')+common_words)\n",
    "        for text in texts:\n",
    "            new_text = [t for t in text if t.lower() not in stop]\n",
    "            final = \" \".join(new_text)\n",
    "            texts_out.append(final)\n",
    "        return (texts_out)\n",
    "\n",
    "    stop_word_removed_texts = stop_word_removal(lemmatized_texts)\n",
    "\n",
    "    def gen_words(texts):\n",
    "        final = []\n",
    "        for text in texts:\n",
    "            new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "            final.append(new)\n",
    "        return (final)\n",
    "\n",
    "    data_words = gen_words(stop_word_removed_texts)\n",
    "\n",
    "\n",
    "    # Create bigrams and trigrams\n",
    "    bigram_phrases = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "    trigram_phrases = gensim.models.Phrases(bigram_phrases[data_words], threshold=100)\n",
    "\n",
    "    bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "    trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "\n",
    "    def make_bigrams(texts):\n",
    "        return([bigram[doc] for doc in texts])\n",
    "\n",
    "    def make_trigrams(texts):\n",
    "        return ([trigram[bigram[doc]] for doc in texts])\n",
    "\n",
    "    data_bigrams = make_bigrams(data_words)\n",
    "    data_bigrams_trigrams = make_trigrams(data_bigrams)\n",
    "\n",
    "\n",
    "    return data_bigrams_trigrams\n",
    "\n",
    "texts = prepare_text(f_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 16131 clusters with 20 clusters populated\n",
      "In stage 1: transferred 2101 clusters with 20 clusters populated\n",
      "In stage 2: transferred 557 clusters with 20 clusters populated\n",
      "In stage 3: transferred 388 clusters with 20 clusters populated\n",
      "In stage 4: transferred 347 clusters with 20 clusters populated\n",
      "In stage 5: transferred 330 clusters with 20 clusters populated\n",
      "In stage 6: transferred 310 clusters with 20 clusters populated\n",
      "In stage 7: transferred 314 clusters with 20 clusters populated\n",
      "In stage 8: transferred 308 clusters with 20 clusters populated\n",
      "In stage 9: transferred 320 clusters with 20 clusters populated\n",
      "In stage 10: transferred 304 clusters with 20 clusters populated\n",
      "In stage 11: transferred 305 clusters with 20 clusters populated\n",
      "In stage 12: transferred 279 clusters with 20 clusters populated\n",
      "In stage 13: transferred 290 clusters with 20 clusters populated\n",
      "In stage 14: transferred 299 clusters with 20 clusters populated\n",
      "In stage 15: transferred 291 clusters with 20 clusters populated\n",
      "In stage 16: transferred 300 clusters with 20 clusters populated\n",
      "In stage 17: transferred 302 clusters with 20 clusters populated\n",
      "In stage 18: transferred 297 clusters with 20 clusters populated\n",
      "In stage 19: transferred 290 clusters with 20 clusters populated\n",
      "In stage 20: transferred 290 clusters with 20 clusters populated\n",
      "In stage 21: transferred 280 clusters with 20 clusters populated\n",
      "In stage 22: transferred 285 clusters with 20 clusters populated\n",
      "In stage 23: transferred 271 clusters with 20 clusters populated\n",
      "In stage 24: transferred 279 clusters with 20 clusters populated\n",
      "In stage 25: transferred 287 clusters with 20 clusters populated\n",
      "In stage 26: transferred 281 clusters with 20 clusters populated\n",
      "In stage 27: transferred 285 clusters with 20 clusters populated\n",
      "In stage 28: transferred 285 clusters with 20 clusters populated\n",
      "In stage 29: transferred 305 clusters with 20 clusters populated\n"
     ]
    }
   ],
   "source": [
    "def gsdmm(texts, num_topics):\n",
    "    #mgp topic modeling\n",
    "    mgp = MovieGroupProcess(K=num_topics, alpha=0.01, beta=0.01, n_iters=30)\n",
    "\n",
    "    vocab = set(x for t in texts for x in t)\n",
    "    n_terms = len(vocab)\n",
    "    model = mgp.fit(texts, n_terms)\n",
    "\n",
    "    return mgp\n",
    "\n",
    "mgp = gsdmm(texts, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [ 299  514  510  726  802  590 1504  568 2987 1105  548  860  738 1186\n",
      " 1352 1188  736  695  616  491]\n",
      "********************\n",
      "Most important clusters (by number of docs inside): [ 8  6 14 15 13  9 11  4 12 16  3 17 18  5  7 10  1  2 19  0]\n",
      "********************\n",
      "\n",
      "Cluster 8 : [('faculty', 1338), ('engineering', 1276), ('interest', 1204), ('laboratory', 982), ('problem', 883), ('theatre', 852), ('computer', 801), ('research', 735), ('lecture', 685), ('seminar', 685), ('report', 657), ('credit', 637), ('eec', 577), ('hour', 567), ('science', 565), ('supervision', 556), ('area', 548), ('craft', 538), ('work', 534), ('production', 527)]\n",
      "\n",
      "Cluster 6 : [('practice', 2548), ('situation', 2484), ('function', 1466), ('tool', 1370), ('computer', 1354), ('structure', 1308), ('literature', 1242), ('world', 1242), ('time', 1242), ('understanding', 1242), ('history', 1242), ('issue', 1242), ('lecture', 1242), ('politic', 1242), ('content', 1242), ('textbook', 1242), ('feature', 1242), ('society', 1242), ('comprehension', 1242), ('vocabulary', 1242)]\n",
      "\n",
      "Cluster 14 : [('lab', 4410), ('laboratory', 2283), ('datum', 1583), ('hour', 1449), ('principle', 1224), ('science', 1201), ('observation', 1172), ('result', 1163), ('prediction', 1163), ('physics', 1078), ('method', 939), ('instructor', 916), ('information', 780), ('mechanic', 624), ('theory', 615), ('experiment', 574), ('law', 548), ('electricity', 548), ('magnetism', 548), ('period', 529)]\n",
      "\n",
      "Cluster 15 : [('skill', 1176), ('listening', 1055), ('people', 1031), ('opportunity', 993), ('speaking', 970), ('user', 970), ('learning', 968), ('literature', 966), ('insight', 965), ('challenge', 962), ('system', 128), ('information', 100), ('design', 95), ('history', 94), ('community', 75), ('exam', 74), ('network', 71), ('choice', 61), ('practice', 60), ('study', 59)]\n",
      "\n",
      "Cluster 13 : [('history', 855), ('world', 416), ('question', 348), ('study', 315), ('text', 306), ('way', 302), ('century', 287), ('work', 271), ('time', 243), ('literature', 232), ('life', 223), ('development', 222), ('discussion', 217), ('process', 216), ('story', 214), ('section', 205), ('skill', 203), ('environment', 203), ('research', 197), ('state', 196)]\n",
      "\n",
      "Cluster 9 : [('analysis', 645), ('project', 631), ('design', 604), ('report', 424), ('research', 418), ('theory', 283), ('presentation', 264), ('communication', 260), ('computer', 235), ('system', 224), ('datum', 217), ('method', 211), ('user', 205), ('task', 204), ('documentation', 198), ('application', 192), ('science', 188), ('problem', 187), ('process', 185), ('introduction', 184)]\n",
      "\n",
      "Cluster 11 : [('history', 379), ('way', 373), ('life', 355), ('world', 341), ('study', 293), ('knowledge', 276), ('artifact', 276), ('text', 243), ('semester', 228), ('gender', 201), ('level', 199), ('use', 187), ('part', 179), ('production', 173), ('heritage', 160), ('basis', 156), ('end', 155), ('issue', 151), ('source', 144), ('question', 141)]\n",
      "\n",
      "Cluster 4 : [('essay', 2008), ('argument', 1356), ('question', 1335), ('skill', 695), ('peer', 692), ('variety', 690), ('workshop', 683), ('revision', 683), ('instructor', 681), ('genre', 677), ('context', 670), ('thinking', 669), ('editing', 660), ('understanding', 657), ('inquiry', 657), ('writer', 657), ('model', 650), ('prompt', 648), ('practice', 84), ('thing', 63)]\n",
      "\n",
      "Cluster 12 : [('politic', 304), ('history', 281), ('community', 261), ('law', 260), ('issue', 220), ('understanding', 219), ('research', 213), ('time', 206), ('society', 196), ('overview', 178), ('discussion', 175), ('literature', 170), ('leadership', 159), ('series', 151), ('manifestation', 151), ('painting', 150), ('world', 149), ('minority', 148), ('race', 147), ('study', 146)]\n",
      "\n",
      "Cluster 16 : [('term', 1008), ('chemistry', 998), ('biology', 720), ('science', 536), ('sequence', 375), ('major', 370), ('credit', 279), ('statistic', 220), ('datum', 208), ('population', 201), ('context', 200), ('requirement', 196), ('capacity', 196), ('problem', 192), ('emphasis', 191), ('concept', 191), ('development', 187), ('process', 185), ('structure', 182), ('relationship', 179)]\n",
      "\n",
      "Cluster 3 : [('dance', 841), ('genre', 731), ('work', 650), ('section', 643), ('skill', 536), ('listening', 495), ('aspect', 388), ('video', 373), ('year', 258), ('awareness', 254), ('variety', 250), ('expression', 237), ('level', 234), ('analysis', 226), ('assignment', 224), ('performance', 220), ('improvisation', 219), ('instruction', 218), ('hip_hop', 210), ('freedom', 210)]\n",
      "\n",
      "Cluster 17 : [('structure', 492), ('vocabulary', 482), ('listening', 448), ('skill', 290), ('history', 287), ('film', 244), ('detail', 238), ('thesis', 236), ('future', 233), ('machine', 231), ('sentence', 228), ('comparison', 228), ('assignment', 227), ('repetition', 224), ('computation', 210), ('time', 208), ('faculty', 206), ('research', 196), ('introduction', 164), ('member', 144)]\n",
      "\n",
      "Cluster 18 : [('film', 437), ('experience', 425), ('credit', 324), ('video', 312), ('requirement', 266), ('aspect', 260), ('year', 232), ('time', 215), ('difference', 214), ('identity', 202), ('week', 193), ('major', 178), ('production', 172), ('part', 169), ('community', 158), ('area', 156), ('supervision', 156), ('industry', 156), ('preproduction', 156), ('business', 156)]\n",
      "\n",
      "Cluster 5 : [('level', 692), ('discussion', 608), ('computer', 510), ('instructor', 470), ('review', 446), ('para', 441), ('grammar', 440), ('voice', 440), ('example', 440), ('piece', 440), ('movie', 440), ('item', 440), ('preterit', 440), ('ser', 440), ('estar', 440), ('por', 440), ('hardware', 336), ('project', 270), ('understanding', 196), ('exam', 186)]\n",
      "\n",
      "Cluster 7 : [('term', 1002), ('section', 1000), ('seat', 992), ('concept', 944), ('waitlist', 606), ('beginning', 510), ('science', 506), ('schedule', 506), ('goal', 486), ('information', 486), ('period', 486), ('background', 486), ('sequence', 486), ('calculus', 486), ('fall', 486), ('registration', 486), ('break', 486), ('summer', 486), ('webpage', 486), ('theory', 474)]\n",
      "\n",
      "Cluster 10 : [('system', 335), ('change', 187), ('climate', 173), ('life', 142), ('health', 129), ('time', 108), ('discussion', 107), ('research', 99), ('range', 97), ('impact', 95), ('modulation', 93), ('level', 90), ('century', 89), ('pattern', 86), ('lecture', 85), ('term', 81), ('principle', 80), ('dynamic', 78), ('process', 77), ('science', 77)]\n",
      "\n",
      "Cluster 1 : [('exam', 598), ('use', 524), ('introduction', 475), ('unit', 460), ('placement', 443), ('skill', 439), ('participation', 418), ('time', 402), ('portion', 396), ('objective', 328), ('development', 303), ('grammar', 288), ('content', 286), ('approach', 284), ('speaking', 280), ('sequence', 273), ('instruction', 272), ('integrate', 262), ('test', 258), ('program', 255)]\n",
      "\n",
      "Cluster 2 : [('film', 139), ('study', 116), ('performance', 111), ('life', 111), ('music', 109), ('introduction', 107), ('section', 106), ('context', 105), ('discussion', 105), ('system', 100), ('theme', 94), ('reasoning', 92), ('theory', 91), ('people', 87), ('skill', 87), ('time', 86), ('history', 86), ('research', 84), ('movement', 82), ('audience', 82)]\n",
      "\n",
      "Cluster 19 : [('world', 472), ('physics', 370), ('food', 364), ('group', 267), ('lecture', 264), ('field', 262), ('learning', 228), ('experience', 217), ('relationship', 201), ('life', 192), ('science', 191), ('skill', 189), ('technique', 188), ('meeting', 181), ('concept', 171), ('chemistry', 171), ('practice', 169), ('biology', 167), ('medicine', 165), ('century', 162)]\n",
      "\n",
      "Cluster 0 : [('programming', 525), ('datum', 383), ('tool', 380), ('computer', 372), ('program', 365), ('science', 284), ('project', 258), ('major', 254), ('exam', 252), ('structure', 243), ('question', 241), ('repetition', 230), ('skill', 182), ('problem', 173), ('simulation', 157), ('level', 152), ('set', 144), ('world', 143), ('part', 141), ('concept', 137)]\n"
     ]
    }
   ],
   "source": [
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print(\"\\nCluster %s : %s\"%(cluster,sort_dicts))\n",
    "\n",
    "\n",
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "print('*'*20)\n",
    "# Topics sorted by the number of document they are allocated to\n",
    "top_index = doc_count.argsort()[-20:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)\n",
    "print('*'*20)\n",
    "# Show the top 5 words in term frequency for each cluster \n",
    "\n",
    "top_words(mgp.cluster_word_distribution, top_index, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "\n",
    "# filter extreme cases out of dictionary\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "\n",
    "# create variable containing length of dictionary/vocab\n",
    "vocab_length = len(dictionary)\n",
    "\n",
    "# create BOW dictionary\n",
    "bow_corpus = [dictionary.doc2bow(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5409572911065412\n"
     ]
    }
   ],
   "source": [
    "# import library from gensim  \n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# define function to get words in topics\n",
    "def get_topics_lists(model, top_clusters, n_words):\n",
    "    '''\n",
    "    Gets lists of words in topics as a list of lists.\n",
    "    \n",
    "    model: gsdmm instance\n",
    "    top_clusters:  numpy array containing indices of top_clusters\n",
    "    n_words: top n number of words to include\n",
    "    \n",
    "    '''\n",
    "    # create empty list to contain topics\n",
    "    topics = []\n",
    "    \n",
    "    # iterate over top n clusters\n",
    "    for cluster in top_clusters:\n",
    "        #create sorted dictionary of word distributions\n",
    "        sorted_dict = sorted(model.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:n_words]\n",
    "         \n",
    "        #create empty list to contain words\n",
    "        topic = []\n",
    "        \n",
    "        #iterate over top n words in topic\n",
    "        for k,v in sorted_dict:\n",
    "            #append words to topic list\n",
    "            topic.append(k)\n",
    "            \n",
    "        #append topics to topics list    \n",
    "        topics.append(topic)\n",
    "    \n",
    "    return topics\n",
    "\n",
    "# get topics to feed to coherence model\n",
    "topics = get_topics_lists(mgp, top_index, 20) \n",
    "\n",
    "# evaluate model using Topic Coherence score\n",
    "cm_gsdmm = CoherenceModel(topics=topics, \n",
    "                          dictionary=dictionary, \n",
    "                          corpus=bow_corpus, \n",
    "                          texts=texts, \n",
    "                          coherence='c_v')\n",
    "\n",
    "# get coherence value\n",
    "coherence_gsdmm = cm_gsdmm.get_coherence()  \n",
    "\n",
    "print(coherence_gsdmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
